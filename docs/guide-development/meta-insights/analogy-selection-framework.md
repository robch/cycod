# Analogy Selection Framework

## Overview
This document captures our meta learnings from the process of selecting appropriate analogies for technical concepts in documentation. It provides a structured approach to evaluating and selecting effective analogies.

## Key Insights

### Breaking Pattern Dependencies
- We discovered the importance of considering non-sequitur domains to break out of pattern dependencies
- Initial analogies (kitchen, hospital) may create a conceptual gravity that limits creative exploration
- Deliberately exploring unrelated domains yielded fresh perspectives and stronger options

### Systematic Evaluation Criteria
- Developed a multi-axis rating system to objectively evaluate analogy options:
  1. **Familiarity** (1-10): How likely users are to understand the domain without specialized knowledge
  2. **Visual Clarity** (1-10): How easily concepts can be visualized
  3. **Consequence Clarity** (1-10): How clearly the analogy shows the consequences of errors
  4. **Substitute/Default Value Clarity** (1-10): How intuitive alternative/default values are in the domain
  5. **Universal Appeal** (1-10): How broadly the domain appeals across cultures, backgrounds, and experiences

### Junior Developer Perspective
- Prioritizing the perspective of junior developers revealed the critical importance of universal familiarity
- Specialized domains (archaeology, music) scored lower despite interesting conceptual mappings
- The most effective analogies connect to universal human experiences (cooking, eating)
- Visual clarity emerged as a crucial factor for effective learning

### Quantitative + Qualitative Approach
- The combined approach of ratings + narrative analysis provided more insight than either alone
- Numerical ratings created an objective framework for comparison
- Narrative analysis provided context and nuance that numbers alone couldn't capture
- Together they created a defensible, thoughtful selection process

## Actionable Framework for Future Analogy Selection

1. **Generate Diverse Options**
   - Include both obvious domain connections and non-sequitur options
   - Aim for at least 5 distinct analogy domains
   - Map key technical concepts to each domain

2. **Apply Multi-Axis Evaluation**
   - Rate each analogy on the five key axes (1-10 scale)
   - Calculate total scores for initial ranking
   - Identify specific strengths and weaknesses of each

3. **Consider Audience Perspective**
   - Explicitly evaluate from the learner's viewpoint
   - Prioritize universal experiences over specialized knowledge
   - Consider cultural and background diversity

4. **Test Conceptual Coverage**
   - Ensure the selected analogy adequately covers all key technical aspects
   - Identify any concepts that might not translate well
   - Consider hybrid approaches when necessary for complete coverage

5. **Document Decision Rationale**
   - Capture both quantitative ratings and qualitative reasoning
   - Note the specific strengths that led to selection
   - Document any potential weaknesses to address during development